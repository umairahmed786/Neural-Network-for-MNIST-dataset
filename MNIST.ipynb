{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "2811dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "\n",
    "mnist.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "1e493dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, t_train, x_test, t_test = mnist.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "de6e9ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(1, 60000)\n",
      "(784, 10000)\n",
      "(1, 10000)\n"
     ]
    }
   ],
   "source": [
    "x_train=x_train.T\n",
    "t_train=t_train.T.reshape(1,-1)\n",
    "x_test=x_test.T\n",
    "t_test=t_test.reshape(1,-1)\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "aff19a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img = x_train[:,0].reshape(28,28) # First image in the training set.\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()\n",
    "print(t_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "e07ceeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 60000)\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train=x_train/255\n",
    "x_test=x_test/255\n",
    "\n",
    "y_train=np.zeros((10,60000))\n",
    "y_test=np.zeros((10,10000))\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "454f98b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the output into 10 by 1 for each input and place 1 which index corresponds to the ouput of the given image\n",
    "for i in range(0,y_train.shape[1]):\n",
    "    y_train[t_train[0][i]][i]=1\n",
    "for i in range(0,y_test.shape[1]):\n",
    "    y_test[t_test[0][i]][i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "73ae6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    s=1/(1+np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "a7364b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: Relu\n",
    "\n",
    "def relu(z):\n",
    "    s=np.maximum(0,z)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "562eed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dev_relu(a):\n",
    "    x=np.copy(a)\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "9dc15f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: Liky Relu\n",
    "\n",
    "def likyrelu(z):\n",
    "    s=np.maximum(0.01*z , z)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "19f918d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dev_likyrelu(a):\n",
    "    x=np.copy(a)\n",
    "    x[x<0] = 0.01\n",
    "    x[x>=0] = 1\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "f0b95161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"    \n",
    "    W1=np.random.randn(n_h,n_x) * 0.01\n",
    "    b1=np.zeros((n_h,1))\n",
    "    W2=np.random.randn(n_y,n_h) * 0.01\n",
    "    b2=np.zeros((n_y,1))\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b844c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION:forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- input data of size (n_x, m)\n",
    "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "    \n",
    "    Returns:\n",
    "    A2 -- The sigmoid output of the second activation\n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    \"\"\"\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    \n",
    "    W1=parameters[\"W1\"]\n",
    "    b1=parameters[\"b1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    b2=parameters[\"b2\"]\n",
    "    \n",
    " \n",
    "    \n",
    "    # Implement Forward Propagation to calculate A2 (probabilities)\n",
    "    \n",
    "    Z1=np.dot(W1,X)+b1\n",
    "    A1=relu(Z1)\n",
    "    Z2=np.dot(W2,A1)+b2\n",
    "    A2=sigmoid(Z2)\n",
    "   \n",
    "    \n",
    "    assert(A2.shape == (10, X.shape[1]))\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d6af2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y):\n",
    "    \"\"\"\n",
    "    Computes the cross-entropy cost given in equation (13)\n",
    "    \n",
    "    Arguments:\n",
    "    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost given equation (13)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1] # number of examples\n",
    "\n",
    "    # Compute the cross-entropy cost\n",
    "   \n",
    "    Logprobs=np.sum(np.multiply(Y,np.log(A2))+np.multiply((1-Y),np.log(1-A2)),axis=1,keepdims=True)\n",
    "    Logprobs=Logprobs/10\n",
    "    cost=(-1/m)*np.sum(Logprobs)\n",
    "    \n",
    "    \n",
    "    cost = float(np.squeeze(cost))  # makes sure cost is the dimension we expect. \n",
    "                                    # E.g., turns [[17]] into 17 \n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "6e950b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: backward_propagation\n",
    "\n",
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation using the instructions above.\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing our parameters \n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
    "    X -- input data of shape (2, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    grads -- python dictionary containing your gradients with respect to different parameters\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
    "    W1=parameters[\"W1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    \n",
    "    # Retrieve also A1 and A2 from dictionary \"cache\".\n",
    "    A1=cache[\"A1\"]\n",
    "    A2=cache[\"A2\"]\n",
    "    \n",
    "    \n",
    "    # Backward propagation: calculate dW1, db1, dW2, db2. \n",
    "    dZ2=A2-Y/10\n",
    "    dW2=np.dot(dZ2,A1.T)/m\n",
    "    db2=np.sum(dZ2,axis=1,keepdims=True)/m\n",
    "#     dZ1=np.dot(W2.T,dZ2)*(A1*(A1-1))\n",
    "    \n",
    "    dZ1=np.dot(W2.T,dZ2)*(dev_relu(A1))\n",
    "#     dZ1=np.dot(W2.T,dZ2)*(1 - np.power(A1, 2))\n",
    "    dW1=np.dot(dZ1,X.T)/m\n",
    "    db1=np.sum(dZ1,axis=1,keepdims=True)/m\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "2c3d0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: update_parameters\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate = 1.2):\n",
    "    \"\"\"\n",
    "    Updates parameters using the gradient descent update rule given above\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "    # Retrieve a copy of each parameter from the dictionary \"parameters\". Use copy.deepcopy(...) for W1 and W2\n",
    "    W1=parameters[\"W1\"]\n",
    "    b1=parameters[\"b1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    b2=parameters[\"b2\"]\n",
    "    \n",
    "    # Retrieve each gradient from the dictionary \"grads\"\n",
    "    dW1=grads[\"dW1\"]\n",
    "    db1=grads[\"db1\"]\n",
    "    dW2=grads[\"dW2\"]\n",
    "    db2=grads[\"db2\"]\n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    W1=W1-learning_rate*dW1\n",
    "    W2=W2-learning_rate*dW2\n",
    "    b1=b1-learning_rate*db1\n",
    "    b2=b2-learning_rate*db2\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "9681fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: nn_model\n",
    "\n",
    "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- dataset of shape (2, number of examples)\n",
    "    Y -- labels of shape (1, number of examples)\n",
    "    n_h -- size of the hidden layer\n",
    "    num_iterations -- Number of iterations in gradient descent loop\n",
    "    print_cost -- if True, print the cost every 1000 iterations\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_x = X.shape[0]\n",
    "    n_y = Y.shape[0]\n",
    "    \n",
    "    # Initialize parameters\n",
    "    #(≈ 1 line of code)\n",
    "    # parameters = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    parameters=initialize_parameters(n_x, n_h, n_y)\n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        #(≈ 4 lines of code)\n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        # A2, cache = ...\n",
    "        \n",
    "        # Cost function. Inputs: \"A2, Y\". Outputs: \"cost\".\n",
    "        # cost = ...\n",
    " \n",
    "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        # grads = ...\n",
    " \n",
    "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        # parameters = ...\n",
    "        \n",
    "        # YOUR CODE STARTS HERE\n",
    "        A2,cache=forward_propagation(X, parameters)\n",
    "        cost=compute_cost(A2, Y)\n",
    "        grads=backward_propagation(parameters, cache, X, Y)\n",
    "        parameters=update_parameters(parameters, grads, learning_rate = 1.2)\n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "        # Print the cost every 1000 iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "861a1206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693203\n",
      "Cost after iteration 100: 0.330347\n",
      "Cost after iteration 200: 0.270665\n",
      "Cost after iteration 300: 0.266274\n",
      "Cost after iteration 400: 0.263818\n",
      "Cost after iteration 500: 0.263339\n",
      "Cost after iteration 600: 0.263430\n",
      "Cost after iteration 700: 0.263608\n",
      "Cost after iteration 800: 0.264457\n",
      "Cost after iteration 900: 0.268681\n"
     ]
    }
   ],
   "source": [
    "n_h=18\n",
    "parameters=nn_model(x_train, y_train, n_h, num_iterations = 1000, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "0ffcaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    \"\"\"\n",
    "    Using the learned parameters, predicts a class for each example in X\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    X -- input data of size (n_x, m)\n",
    "    \n",
    "    Returns\n",
    "    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
    "    #(≈ 2 lines of code)\n",
    "    # A2, cache = ...\n",
    "    # predictions = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    A2,cahche=forward_propagation(X, parameters)\n",
    "    \n",
    "    prediction=np.zeros([10,10000])\n",
    "    \n",
    "    for i in range(0,A2.shape[1]):\n",
    "        index=A2[:,i].argmax()\n",
    "        prediction[index][i]=1\n",
    "                        \n",
    "\n",
    "    # YOUR CODE ENDS HERE\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "7717b447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "test accuracy: 98.466 %\n"
     ]
    }
   ],
   "source": [
    "prediction=predict(parameters,x_test)\n",
    "# print(A2.shape)\n",
    "print(prediction[:,8000])\n",
    "# print(y_test[:,0])\n",
    "\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(prediction - y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "8268a8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "ind=8524\n",
    "img = x_test[:,ind].reshape(28,28) # First image in the training set.\n",
    "plt.imshow(img,cmap='gray')\n",
    "plt.show()\n",
    "print(prediction[:,ind].argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52fe42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
